{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from typing import Dict, List\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mars.movement import *\n",
    "from mars.tool import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mars.action import Action, ActionType\n",
    "import mars.serializer as ms\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson import ObjectId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_point_from_row(df_row_data):\n",
    "\n",
    "    vector = np.array([\n",
    "        df_row_data.x_j1,\n",
    "        df_row_data.y_j2,\n",
    "        df_row_data.z_j3,\n",
    "        df_row_data.w_j4,\n",
    "        df_row_data.p_j5,\n",
    "        df_row_data.r_j6\n",
    "    ])\n",
    "\n",
    "    e1 = df_row_data.e1\n",
    "    speed = df_row_data.speed\n",
    "    cnt = df_row_data.cnt\n",
    "    path = df_row_data.path\n",
    "    pos_type = df_row_data.position_type\n",
    "\n",
    "    if pos_type == \"JOINT\":\n",
    "        position = PositionJoint(vector, e1)\n",
    "    else:\n",
    "        wrist = WristConfig.FLIP if df_row_data.wrist =='F' else WristConfig.NOFLIP\n",
    "        forearm = ForeArmConfig.UP if df_row_data.forearm == 'U' else ForeArmConfig.DOWN\n",
    "        arm = ArmConfig.TOWARD if df_row_data.arm =='T' else ArmConfig.BACKWARD\n",
    "\n",
    "        config = Configuration(wrist, forearm, arm)\n",
    "        position = PositionCrt(vector, e1, config)\n",
    "\n",
    "    path = Path[df_row_data.path]\n",
    "\n",
    "    return Point(cnt, speed, path, position)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def serialize_for_mongo(action, up_dependences_ids, down_dependences_ids):\n",
    "    \n",
    "    action_doc = action.to_dict()\n",
    "    del(action_doc['id'])\n",
    "\n",
    "    if up_dependences_ids:\n",
    "        action_doc['UPSTREAM_dependences'] = up_dependences_ids\n",
    "\n",
    "    if down_dependences_ids:\n",
    "        action_doc['DOWNSTREAM_dependences'] = down_dependences_ids\n",
    "\n",
    "    return action_doc\n",
    "\"\"\"\n",
    "\n",
    "def save_in_mongo(action_dict: Dict or List[Dict]):\n",
    "    \n",
    "    c = MongoClient()\n",
    "    carrier = c.get_database('mars').get_collection('carrier')\n",
    "\n",
    "    if type(action_dict) == list:\n",
    "        res = carrier.insert_many(action_dict)\n",
    "    else:\n",
    "        res = carrier.insert_one(action_dict)\n",
    "\n",
    "    if not res.acknowledged :\n",
    "        raise Exception(\"Error during insertion\")\n",
    "        \n",
    "    else :\n",
    "        if type(action_dict) == list:\n",
    "            print('insertion success, document id : ', str(res.inserted_ids))\n",
    "            return res.inserted_ids\n",
    "        else :\n",
    "            print('insertion success, document id : ', str(res.inserted_id))\n",
    "            return res.inserted_id\n",
    "\n",
    "    \"\"\"\n",
    "    if type(action) == list:\n",
    "        actions_docs = []\n",
    "        for a in action:\n",
    "            if type(a) == tuple:\n",
    "                action_doc = serialize_for_mongo(a[0], up_dependences_ids, down_dependences_ids)\n",
    "                action_doc.update(a[1])\n",
    "            else:\n",
    "                action_doc = serialize_for_mongo(a, up_dependences_ids, down_dependences_ids)\n",
    "            \n",
    "            actions_docs.append(action_doc)\n",
    "\n",
    "        res = carrier.insert_many(actions_docs)\n",
    "\n",
    "        if not res.acknowledged :\n",
    "            print('Exception during insertion')\n",
    "            return None\n",
    "        else :\n",
    "            print('insertion success, document id : ', str(res.inserted_ids))\n",
    "            return res.inserted_ids\n",
    "    \n",
    "    else:\n",
    "        if type(action) == tuple:\n",
    "            action_doc = serialize_for_mongo(action[0], up_dependences_ids, down_dependences_ids)\n",
    "            action_doc.update(action[1])\n",
    "        else:\n",
    "            action_doc = serialize_for_mongo(action, up_dependences_ids, down_dependences_ids)\n",
    "\"\"\" \n",
    "\n",
    "def get_action_type(action: str) :\n",
    "    if(action == 'station'):\n",
    "        return ActionType['MOVE']['STATION']['WORK']\n",
    "    elif (action == 'work'):\n",
    "        return ActionType['MOVE']['ARM']['WORK']\n",
    "    elif (action == 'approach'):\n",
    "        return ActionType['MOVE']['ARM']['APPROACH']\n",
    "    elif (action == 'clearance'):\n",
    "        return ActionType['MOVE']['ARM']['CLEARANCE']\n",
    "    elif (action == 'home'):\n",
    "        return ActionType['MOVE']['STATION']['HOME']\n",
    "    elif (action == 'load_tool'):\n",
    "        return ActionType['MOVE']['STATION']['TOOL']\n",
    "    elif (action == 'unload_tool'):\n",
    "        return ActionType['MOVE']['STATION']['TOOL']\n",
    "    else:\n",
    "        raise Exception(\"default on action type\")\n",
    "\n",
    "def get_action_from_df(action_type: str,\n",
    "                       description: str,\n",
    "                       dataframe: pd.DataFrame) -> Action :\n",
    "    points: List[Point] = []\n",
    "\n",
    "    for line in dataframe.iterrows():\n",
    "        points.append(get_point_from_row(line[1]))\n",
    "    \n",
    "    ut_uf = dataframe[['UT','UF', 'work_order']].drop_duplicates()\n",
    "    ut, uf, work_order = int(ut_uf.iloc[0].UT),\\\n",
    "                         int(ut_uf.iloc[0].UF),\\\n",
    "                         int(ut_uf.iloc[0].work_order) if not pd.isna(ut_uf.iloc[0].work_order) else None\n",
    "\n",
    "    movement = Movement(uf, ut, points)\n",
    "    \n",
    "    return Action(id='',\n",
    "                  atype = get_action_type(action_type),\n",
    "                  definition = movement,\n",
    "                  description = description,\n",
    "                  work_order=work_order)\n",
    "\n",
    "def get_additionnal_info(dataframe: pd.DataFrame, infolist: List[str]):\n",
    "    add_info_df = dataframe[infolist].drop_duplicates()\n",
    "    add_list = [(name, add_info_df.iloc[0][name]) for name in infolist]\n",
    "    add_list = [(name, convert_np(val)) for name, val in add_list]\n",
    "        \n",
    "    return dict(add_list)\n",
    "\n",
    "def convert_np(value):\n",
    "    if type(value) == np.int64:\n",
    "        return int(value)\n",
    "    elif type(value) == np.float64:\n",
    "        return float(value)\n",
    "    else:\n",
    "        return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/C35_web_5mm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insertion success, document id :  home\n",
      "insertion success, document id :  load_tool_position\n",
      "insertion success, document id :  617fca577edfefdb7bd91bb2\n",
      "insertion success, document id :  617fca577edfefdb7bd91bb4\n",
      "insertion success, document id :  617fca577edfefdb7bd91bb6\n",
      "insertion success, document id :  617fca577edfefdb7bd91bb8\n",
      "insertion success, document id :  617fca577edfefdb7bd91bba\n",
      "insertion success, document id :  [ObjectId('617fca577edfefdb7bd91bbc'), ObjectId('617fca577edfefdb7bd91bbd'), ObjectId('617fca577edfefdb7bd91bbe'), ObjectId('617fca577edfefdb7bd91bbf'), ObjectId('617fca577edfefdb7bd91bc0'), ObjectId('617fca577edfefdb7bd91bc1'), ObjectId('617fca577edfefdb7bd91bc2'), ObjectId('617fca577edfefdb7bd91bc3'), ObjectId('617fca577edfefdb7bd91bc4'), ObjectId('617fca577edfefdb7bd91bc5'), ObjectId('617fca577edfefdb7bd91bc6'), ObjectId('617fca577edfefdb7bd91bc7'), ObjectId('617fca577edfefdb7bd91bc8'), ObjectId('617fca577edfefdb7bd91bc9'), ObjectId('617fca577edfefdb7bd91bca'), ObjectId('617fca577edfefdb7bd91bcb'), ObjectId('617fca577edfefdb7bd91bcc'), ObjectId('617fca577edfefdb7bd91bcd'), ObjectId('617fca577edfefdb7bd91bce'), ObjectId('617fca577edfefdb7bd91bcf'), ObjectId('617fca577edfefdb7bd91bd0'), ObjectId('617fca577edfefdb7bd91bd1'), ObjectId('617fca577edfefdb7bd91bd2'), ObjectId('617fca577edfefdb7bd91bd3'), ObjectId('617fca577edfefdb7bd91bd4'), ObjectId('617fca577edfefdb7bd91bd5')]\n",
      "insertion success, document id :  617fca577edfefdb7bd91bd7\n",
      "insertion success, document id :  617fca577edfefdb7bd91bd9\n",
      "insertion success, document id :  617fca587edfefdb7bd91bdb\n",
      "insertion success, document id :  [ObjectId('617fca587edfefdb7bd91bdd'), ObjectId('617fca587edfefdb7bd91bde'), ObjectId('617fca587edfefdb7bd91bdf'), ObjectId('617fca587edfefdb7bd91be0'), ObjectId('617fca587edfefdb7bd91be1'), ObjectId('617fca587edfefdb7bd91be2'), ObjectId('617fca587edfefdb7bd91be3'), ObjectId('617fca587edfefdb7bd91be4'), ObjectId('617fca587edfefdb7bd91be5'), ObjectId('617fca587edfefdb7bd91be6'), ObjectId('617fca587edfefdb7bd91be7'), ObjectId('617fca587edfefdb7bd91be8'), ObjectId('617fca587edfefdb7bd91be9'), ObjectId('617fca587edfefdb7bd91bea'), ObjectId('617fca587edfefdb7bd91beb'), ObjectId('617fca587edfefdb7bd91bec'), ObjectId('617fca587edfefdb7bd91bed'), ObjectId('617fca587edfefdb7bd91bee'), ObjectId('617fca587edfefdb7bd91bef'), ObjectId('617fca587edfefdb7bd91bf0'), ObjectId('617fca587edfefdb7bd91bf1'), ObjectId('617fca587edfefdb7bd91bf2'), ObjectId('617fca587edfefdb7bd91bf3'), ObjectId('617fca587edfefdb7bd91bf4'), ObjectId('617fca587edfefdb7bd91bf5'), ObjectId('617fca587edfefdb7bd91bf6')]\n",
      "insertion success, document id :  617fca587edfefdb7bd91bf8\n",
      "insertion success, document id :  617fca587edfefdb7bd91bfa\n",
      "insertion success, document id :  617fca587edfefdb7bd91bfc\n",
      "insertion success, document id :  [ObjectId('617fca587edfefdb7bd91bfe'), ObjectId('617fca587edfefdb7bd91bff'), ObjectId('617fca587edfefdb7bd91c00'), ObjectId('617fca587edfefdb7bd91c01'), ObjectId('617fca587edfefdb7bd91c02'), ObjectId('617fca587edfefdb7bd91c03'), ObjectId('617fca587edfefdb7bd91c04'), ObjectId('617fca587edfefdb7bd91c05'), ObjectId('617fca587edfefdb7bd91c06'), ObjectId('617fca587edfefdb7bd91c07'), ObjectId('617fca587edfefdb7bd91c08'), ObjectId('617fca587edfefdb7bd91c09'), ObjectId('617fca587edfefdb7bd91c0a'), ObjectId('617fca587edfefdb7bd91c0b'), ObjectId('617fca587edfefdb7bd91c0c'), ObjectId('617fca587edfefdb7bd91c0d'), ObjectId('617fca587edfefdb7bd91c0e'), ObjectId('617fca587edfefdb7bd91c0f')]\n",
      "insertion success, document id :  617fca587edfefdb7bd91c11\n",
      "insertion success, document id :  617fca587edfefdb7bd91c13\n",
      "insertion success, document id :  617fca587edfefdb7bd91c15\n",
      "insertion success, document id :  [ObjectId('617fca587edfefdb7bd91c17'), ObjectId('617fca587edfefdb7bd91c18'), ObjectId('617fca587edfefdb7bd91c19'), ObjectId('617fca587edfefdb7bd91c1a'), ObjectId('617fca587edfefdb7bd91c1b'), ObjectId('617fca587edfefdb7bd91c1c'), ObjectId('617fca587edfefdb7bd91c1d'), ObjectId('617fca587edfefdb7bd91c1e'), ObjectId('617fca587edfefdb7bd91c1f'), ObjectId('617fca587edfefdb7bd91c20'), ObjectId('617fca587edfefdb7bd91c21'), ObjectId('617fca587edfefdb7bd91c22'), ObjectId('617fca587edfefdb7bd91c23'), ObjectId('617fca587edfefdb7bd91c24'), ObjectId('617fca587edfefdb7bd91c25'), ObjectId('617fca587edfefdb7bd91c26'), ObjectId('617fca587edfefdb7bd91c27'), ObjectId('617fca587edfefdb7bd91c28')]\n",
      "insertion success, document id :  617fca587edfefdb7bd91c2a\n",
      "insertion success, document id :  617fca587edfefdb7bd91c2c\n",
      "insertion success, document id :  617fca587edfefdb7bd91c2e\n",
      "insertion success, document id :  [ObjectId('617fca587edfefdb7bd91c30'), ObjectId('617fca587edfefdb7bd91c31'), ObjectId('617fca587edfefdb7bd91c32'), ObjectId('617fca587edfefdb7bd91c33'), ObjectId('617fca587edfefdb7bd91c34'), ObjectId('617fca587edfefdb7bd91c35'), ObjectId('617fca587edfefdb7bd91c36'), ObjectId('617fca587edfefdb7bd91c37'), ObjectId('617fca587edfefdb7bd91c38'), ObjectId('617fca587edfefdb7bd91c39'), ObjectId('617fca587edfefdb7bd91c3a'), ObjectId('617fca587edfefdb7bd91c3b'), ObjectId('617fca587edfefdb7bd91c3c'), ObjectId('617fca587edfefdb7bd91c3d'), ObjectId('617fca587edfefdb7bd91c3e'), ObjectId('617fca587edfefdb7bd91c3f'), ObjectId('617fca587edfefdb7bd91c40'), ObjectId('617fca587edfefdb7bd91c41'), ObjectId('617fca587edfefdb7bd91c42'), ObjectId('617fca587edfefdb7bd91c43'), ObjectId('617fca587edfefdb7bd91c44'), ObjectId('617fca587edfefdb7bd91c45'), ObjectId('617fca587edfefdb7bd91c46'), ObjectId('617fca587edfefdb7bd91c47'), ObjectId('617fca587edfefdb7bd91c48'), ObjectId('617fca587edfefdb7bd91c49')]\n",
      "insertion success, document id :  617fca587edfefdb7bd91c4b\n",
      "insertion success, document id :  617fca597edfefdb7bd91c4d\n",
      "insertion success, document id :  617fca597edfefdb7bd91c4f\n",
      "insertion success, document id :  [ObjectId('617fca597edfefdb7bd91c51'), ObjectId('617fca597edfefdb7bd91c52'), ObjectId('617fca597edfefdb7bd91c53'), ObjectId('617fca597edfefdb7bd91c54'), ObjectId('617fca597edfefdb7bd91c55'), ObjectId('617fca597edfefdb7bd91c56'), ObjectId('617fca597edfefdb7bd91c57'), ObjectId('617fca597edfefdb7bd91c58'), ObjectId('617fca597edfefdb7bd91c59'), ObjectId('617fca597edfefdb7bd91c5a'), ObjectId('617fca597edfefdb7bd91c5b'), ObjectId('617fca597edfefdb7bd91c5c'), ObjectId('617fca597edfefdb7bd91c5d'), ObjectId('617fca597edfefdb7bd91c5e'), ObjectId('617fca597edfefdb7bd91c5f'), ObjectId('617fca597edfefdb7bd91c60'), ObjectId('617fca597edfefdb7bd91c61'), ObjectId('617fca597edfefdb7bd91c62'), ObjectId('617fca597edfefdb7bd91c63'), ObjectId('617fca597edfefdb7bd91c64'), ObjectId('617fca597edfefdb7bd91c65'), ObjectId('617fca597edfefdb7bd91c66'), ObjectId('617fca597edfefdb7bd91c67'), ObjectId('617fca597edfefdb7bd91c68'), ObjectId('617fca597edfefdb7bd91c69'), ObjectId('617fca597edfefdb7bd91c6a')]\n"
     ]
    }
   ],
   "source": [
    "# return home and go home action\n",
    "df_home = df[df.mvt =='home']\n",
    "df_tool = df[df.mvt ==\"tool\"]\n",
    "df_station = df[df.mvt == \"station\"]\n",
    "df_approach = df[df.mvt == \"approach\"]\n",
    "df_clearance = df[df.mvt == \"clearance\"]\n",
    "df_work = df[df.mvt == \"work\"]\n",
    "\n",
    "rails = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "go_home = get_action_from_df('home', 'go on home position', df_home)\n",
    "go_tool = get_action_from_df('load_tool', 'go to load/unload tool position', df_tool)\n",
    "\n",
    "go_home = go_home.to_dict()\n",
    "go_home['_id'] = 'home'\n",
    "go_home_id = save_in_mongo(go_home)\n",
    "\n",
    "go_tool = go_tool.to_dict()\n",
    "go_tool['_id'] = 'load_tool_position'\n",
    "go_tool_id = save_in_mongo(go_tool)\n",
    "\n",
    "# unload effector\n",
    "ulte_def = UnloadManipulation(3, 1, \"effector\", \"WEBEFFECTOR\")\n",
    "unload_eff = Action('ult', ActionType['UNLOAD']['EFFECTOR'], ulte_def, \"unload web effector\")\n",
    "unload_eff = unload_eff.to_dict()\n",
    "del unload_eff['_id']\n",
    "unload_id = save_in_mongo(unload_eff)\n",
    "\n",
    "\n",
    "# load effector \n",
    "lte_def = LoadManipulation(3, 1, \"effector\", \"WEBEFFECTOR\")\n",
    "load_eff= Action('lt', ActionType['LOAD']['EFFECTOR'], lte_def, \"load web effector\")\n",
    "load_eff = load_eff.to_dict()\n",
    "del load_eff['_id']\n",
    "\n",
    "\n",
    "\n",
    "# load_eff['UPSTREAM_dependences'] = [go_tool_id]\n",
    "# load_eff['DOWNSTREAM_dependences'] = [ul_id]\n",
    "load_eff['dependences'] = [{'action': unload_id, 'type': 'DOWNSTREAM'}]\n",
    "load_id = save_in_mongo(load_eff)\n",
    "\n",
    "'''\n",
    "# load drill tool\n",
    "ltd_def = LoadManipulation(3,1,\"drill\", \"4.1_DRILL\")\n",
    "load_drill = Action('lt', ActionType['LOAD']['TOOL'], ltd_def, \"load drill tool\")\n",
    "\n",
    "# unload drill tool\n",
    "ultd_def = UnloadManipulation(3,1,\"drill\", \"4.1_DRILL\")\n",
    "unload_eff = Action('ult', ActionType['UNLOAD']['TOOL'], ulte_def, \"unload drill tool\")\n",
    "'''\n",
    "\n",
    "\n",
    "for rail in rails: \n",
    "\n",
    "  # prepare and insert station mvt in mongo\n",
    "  df_temp = df_station[df_station.rail==rail]\n",
    "  station = get_action_from_df('station',\n",
    "                              'station movement on rail {rail}'.format(rail=rail),\n",
    "                              df_temp)\n",
    "\n",
    "  station = station.to_dict()\n",
    "  add_info = get_additionnal_info(df_temp, ['designation', 'reference', 'id'])\n",
    "  del station['_id']\n",
    "  # station['UPSTREAM_dependences'] = [gh_id]\n",
    "  station['product_reference'] = {\n",
    "    \"designation\": add_info['designation'],\n",
    "    \"reference\": add_info['reference'],\n",
    "    \"id\": add_info['id']\n",
    "  }\n",
    "\n",
    "  # station['work_order'] = add_info['work_order']\n",
    "\n",
    "  station_id = save_in_mongo(station)\n",
    "\n",
    "  # prepare and insert clearance mvt in mongo\n",
    "  df_temp = df_clearance[df_clearance.rail==rail]\n",
    "  clearance = get_action_from_df('clearance',\n",
    "                              'clearance movement from rail {rail}'.format(rail=rail),\n",
    "                              df_temp)\n",
    "  clearance = clearance.to_dict()\n",
    "  del clearance['_id']\n",
    "  clearance['product_reference'] = deepcopy(station['product_reference'])\n",
    "\n",
    "  clearance_id = save_in_mongo(clearance)\n",
    "\n",
    "  # prepare and insert approach mvt in mongo\n",
    "  df_temp = df_approach[df_approach.rail==rail]\n",
    "  approach = get_action_from_df('approach',\n",
    "                              'approach movement to rail {rail}'.format(rail=rail),\n",
    "                              df_temp)\n",
    "\n",
    "  approach = approach.to_dict()\n",
    "  del approach['_id']\n",
    "  approach['product_reference'] = deepcopy(station['product_reference'])\n",
    "  # approach['UPSTREAM_dependences'] = [le_id, station_id]\n",
    "  # approach['DOWNSTREAM_dependences'] = [clearance_id]\n",
    "  approach['dependences'] = [{'action':load_id, 'type': 'UPSTREAM'},\n",
    "                             {'action':station_id, 'type': 'UPSTREAM'},\n",
    "                             {'action':clearance_id, 'type': 'DOWNSTREAM'}]\n",
    "  \n",
    "  # approach['work_order']= station['work_order']\n",
    "\n",
    "  approach_id = save_in_mongo(approach)\n",
    "\n",
    "  # prepare and insert work mvt in mongo\n",
    "  df_temp = df_work[df_work.rail==rail]\n",
    "  w_actions = []\n",
    "  id_list = [item[1] for item in df_temp.id.iteritems()]\n",
    "\n",
    "  for id in id_list :\n",
    "    df_w = df_temp[df_temp.id == id]\n",
    "    add_info = get_additionnal_info(df_w, ['designation', 'reference', 'id'])\n",
    "    wa = get_action_from_df('work',\n",
    "        'work movement on location of fastener {ref}.{id} of rail {rail}'\n",
    "        .format(ref=add_info['reference'], id=add_info['id'], rail=rail),\n",
    "        df_w)\n",
    "    wa = wa.to_dict()\n",
    "    del wa['_id']\n",
    "    wa['product_reference'] = {\n",
    "      \"designation\": add_info['designation'],\n",
    "      \"reference\": add_info['reference'], \n",
    "      \"id\": add_info['id'],\n",
    "      \"parent\": deepcopy(station['product_reference'])\n",
    "    }\n",
    "    # wa['work_order'] = add_info['work_order']\n",
    "    # wa['UPSTREAM_dependences'] = [approach_id]\n",
    "    wa['dependences'] = [{'action':approach_id, 'type': 'UPSTREAM'}]\n",
    "    w_actions.append(wa)\n",
    "\n",
    "  work_ids = save_in_mongo(w_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9ed314b904907a4c4e53c9fcb6bf4c0c17cbf8e65a4ac8bddd1024b2b151b75"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 32-bit ('mars': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
